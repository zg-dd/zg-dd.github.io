<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='核心概念通俗解释\r什么是 topK？\rtopK 就是"前 K 个最相似的结果"。\n例如：topK=5 表示返回最相似的 5 条数据 例如：topK=100 表示返回最相似的 100 条数据 类比：就像在淘宝搜索"手机"，你只看前 10 个商品，这个 10 就是 topK 什么是召回率（Recall）？\r召回率 是衡量搜索准确性的指标，表示"找到了多少个真正相似的结果"。\n'><title>Milvus 索引详解 - 向量搜索性能优化指南</title><link rel=canonical href=https://zg-dd.github.io/stu/milvus-index-explained/><link rel=stylesheet href=/scss/style.min.ff560f1cad7a040e336f2dd6880b9ee1ad344d6e3d8f5411e5a1aaa8b23bbdd0.css><meta property='og:title' content="Milvus 索引详解 - 向量搜索性能优化指南"><meta property='og:description' content='核心概念通俗解释\r什么是 topK？\rtopK 就是"前 K 个最相似的结果"。\n例如：topK=5 表示返回最相似的 5 条数据 例如：topK=100 表示返回最相似的 100 条数据 类比：就像在淘宝搜索"手机"，你只看前 10 个商品，这个 10 就是 topK 什么是召回率（Recall）？\r召回率 是衡量搜索准确性的指标，表示"找到了多少个真正相似的结果"。\n'><meta property='og:url' content='https://zg-dd.github.io/stu/milvus-index-explained/'><meta property='og:site_name' content='小巷的随笔'><meta property='og:type' content='article'><meta property='article:section' content='Stu'><meta property='article:tag' content='Milvus'><meta property='article:tag' content='Index'><meta property='article:published_time' content='2026-02-27T19:11:18+08:00'><meta property='article:modified_time' content='2026-02-27T19:11:18+08:00'><meta name=twitter:title content="Milvus 索引详解 - 向量搜索性能优化指南"><meta name=twitter:description content='核心概念通俗解释\r什么是 topK？\rtopK 就是"前 K 个最相似的结果"。\n例如：topK=5 表示返回最相似的 5 条数据 例如：topK=100 表示返回最相似的 100 条数据 类比：就像在淘宝搜索"手机"，你只看前 10 个商品，这个 10 就是 topK 什么是召回率（Recall）？\r召回率 是衡量搜索准确性的指标，表示"找到了多少个真正相似的结果"。\n'></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_a0cc1cf57968b27d.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌱</span></figure><div class=site-meta><h1 class=site-name><a href=/>小巷的随笔</a></h1><h2 class=site-description>记录，不是为了证明自己；而是把“解决问题 → 思考 → 沉淀”形成习惯。</h2></div></header><ol class=menu id=main-menu><li class=current><a href=/stu/><span>学习笔记</span></a></li><li><a href=/blog/><span>随笔思考</span></a></li><li><a href=/life/><span>生活记录</span></a></li><li><a href=/categories/><span>分类</span></a></li><li><a href=/tags/><span>标签</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://zg-dd.github.io/ selected>简体中文</option><option value=https://zg-dd.github.io/en/>English</option></select></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ul><li><a href=#核心概念通俗解释>核心概念通俗解释</a><ul><li><a href=#什么是-topk>什么是 topK？</a></li><li><a href=#什么是召回率recall>什么是召回率（Recall）？</a></li><li><a href=#什么是过滤率filter-ratio>什么是过滤率（Filter Ratio）？</a></li><li><a href=#什么是容量capacity>什么是容量（Capacity）？</a></li><li><a href=#什么是-autoindex自动索引>什么是 AutoIndex（自动索引）？</a></li></ul></li><li><a href=#为什么需要索引>为什么需要索引</a></li><li><a href=#支持的索引类型supported-index-types>支持的索引类型（Supported Index Types）</a></li><li><a href=#向量索引的内部结构vector-index-anatomy>向量索引的内部结构（Vector Index Anatomy）</a><ul><li><a href=#常见数据结构>常见数据结构</a></li><li><a href=#量化方法>量化方法</a></li><li><a href=#精炼器refiner>精炼器（Refiner）</a></li></ul></li><li><a href=#性能权衡与推荐使用场景>性能权衡与推荐使用场景</a><ul><li><a href=#容量capacity建议>容量（Capacity）建议</a></li><li><a href=#召回率recall与过滤率filter-ratio>召回率（Recall）与过滤率（Filter Ratio）</a></li><li><a href=#性能决策矩阵推荐场景>性能决策矩阵（推荐场景）</a></li></ul></li><li><a href=#实际应用场景推荐>实际应用场景推荐</a><ul><li><a href=#场景-1电商商品推荐系统>场景 1：电商商品推荐系统</a></li><li><a href=#场景-2大规模图片搜索>场景 2：大规模图片搜索</a></li><li><a href=#场景-3实时聊天机器人语义搜索>场景 3：实时聊天机器人（语义搜索）</a></li><li><a href=#场景-4视频内容审核>场景 4：视频内容审核</a></li><li><a href=#场景-5用户画像匹配带过滤条件>场景 5：用户画像匹配（带过滤条件）</a></li><li><a href=#场景-6新手快速开发原型>场景 6：新手快速开发原型</a></li></ul></li><li><a href=#内存使用估算示例以-100-万个-128-维向量为例>内存使用估算示例（以 100 万个 128 维向量为例）</a><ul><li><a href=#ivf-系列>IVF 系列</a></li><li><a href=#hnsw-系列>HNSW 系列</a></li></ul></li><li><a href=#度量类型详解metric-types>度量类型详解（Metric Types）</a><ul><li><a href=#什么是度量类型>什么是度量类型？</a></li><li><a href=#支持的度量类型映射表>支持的度量类型映射表</a></li><li><a href=#度量类型特征对比>度量类型特征对比</a></li><li><a href=#1-欧氏距离l2>1. 欧氏距离（L2）</a></li><li><a href=#2-内积ip-inner-product>2. 内积（IP, Inner Product）</a></li><li><a href=#3-余弦相似度cosine>3. 余弦相似度（COSINE）</a></li><li><a href=#4-杰卡德距离jaccard>4. 杰卡德距离（JACCARD）</a></li><li><a href=#5-minhash-杰卡德mhjaccard>5. MinHash 杰卡德（MHJACCARD）</a></li><li><a href=#6-汉明距离hamming>6. 汉明距离（HAMMING）</a></li><li><a href=#7-bm25-相似度>7. BM25 相似度</a></li><li><a href=#如何选择度量类型>如何选择度量类型？</a></li><li><a href=#使用示例>使用示例</a></li><li><a href=#性能对比>性能对比</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/>向量数据库</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/stu/milvus-index-explained/>Milvus 索引详解 - 向量搜索性能优化指南</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2026-02-27T19:11:18+08:00>Feb 27, 2026</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 12 分钟</time></div></footer><footer class=article-translations><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><div><a href=https://zg-dd.github.io/en/stu/milvus-index-explained/ class=link>English</a></div></footer></div></header><section class=article-content><h2 id=核心概念通俗解释>核心概念通俗解释</h2><h3 id=什么是-topk>什么是 topK？</h3><p><strong>topK</strong> 就是"前 K 个最相似的结果"。</p><ul><li>例如：topK=5 表示返回最相似的 5 条数据</li><li>例如：topK=100 表示返回最相似的 100 条数据</li><li><strong>类比</strong>：就像在淘宝搜索"手机"，你只看前 10 个商品，这个 10 就是 topK</li></ul><h3 id=什么是召回率recall>什么是召回率（Recall）？</h3><p><strong>召回率</strong> 是衡量搜索准确性的指标，表示"找到了多少个真正相似的结果"。</p><ul><li><strong>公式</strong>：召回率 = 实际找到的相似结果数 / 理论上应该找到的相似结果数</li><li><strong>例子</strong>：假设真正最相似的 10 个结果中，你的搜索找到了 9 个，召回率就是 90%</li><li><strong>类比</strong>：就像考试，满分 100 分你考了 95 分，召回率就是 95%</li><li><strong>重要性</strong>：召回率越高，搜索结果越准确，但速度可能越慢</li></ul><h3 id=什么是过滤率filter-ratio>什么是过滤率（Filter Ratio）？</h3><p><strong>过滤率</strong> 是指通过条件筛选后，剩余数据占总数据的比例。</p><ul><li><strong>公式</strong>：过滤率 = (总数据量 - 筛选后剩余数据量) / 总数据量</li><li><strong>例子</strong>：100 万条数据，筛选条件是"价格 > 1000"，剩下 5 万条，过滤率 = (100万-5万)/100万 = 95%</li><li><strong>类比</strong>：就像在图书馆找书，先按"计算机类"筛选掉 90% 的书，过滤率就是 90%</li><li><strong>影响</strong>：过滤率越高，剩余数据越少，暴力搜索可能更快</li></ul><h3 id=什么是容量capacity>什么是容量（Capacity）？</h3><p><strong>容量</strong> 是指你的硬件资源（主要是内存）能存放多少数据。</p><ul><li><strong>内存容量</strong>：你的服务器有多少 RAM 可以用来存放向量数据</li><li><strong>例子</strong>：你有 16GB 内存，向量数据需要 64GB，那么只有 1/4 数据能放入内存</li><li><strong>类比</strong>：就像你的手机存储空间，照片太多就要删一些或放到云盘</li><li><strong>策略</strong>：<ul><li>数据全部能放入内存 → 用内存索引（快）</li><li>数据只有一部分能放入内存 → 用磁盘索引（慢但能处理大数据）</li><li>内存严重不足 → 用压缩索引（牺牲精度换空间）</li></ul></li></ul><h3 id=什么是-autoindex自动索引>什么是 AutoIndex（自动索引）？</h3><p><strong>AutoIndex</strong> 是 Milvus 提供的智能索引选择功能，系统会根据你的数据特征自动选择最合适的索引类型。</p><p><strong>工作原理</strong>：</p><ol><li>分析数据规模、维度、分布特征</li><li>评估硬件资源（内存、CPU、GPU）</li><li>自动选择最优索引类型和参数</li><li>自动构建和优化索引</li></ol><p><strong>适用场景</strong>：</p><ul><li>新手不知道选什么索引</li><li>数据特征复杂，难以手动选择</li><li>快速原型开发，不想花时间调优</li></ul><p><strong>使用方式</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 向量字段使用 AutoIndex</span>
</span></span><span style=display:flex><span>index_params<span style=color:#f92672>.</span>add_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    index_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;AUTOINDEX&#34;</span>,  <span style=color:#75715e># 自动选择索引类型</span>
</span></span><span style=display:flex><span>    metric_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;L2&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 标量字段也可以使用自动索引</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Milvus 会根据字段类型自动选择 INVERTED、BITMAP 或 STL_SORT</span>
</span></span></code></pre></div><p><strong>注意事项</strong>：</p><ul><li>AutoIndex 适合大多数场景，但极端性能要求下建议手动调优</li><li>不同 Milvus 版本的 AutoIndex 策略可能不同</li><li>Zilliz Cloud（托管服务）默认使用 AutoIndex</li></ul><h2 id=为什么需要索引>为什么需要索引</h2><p>索引是建立在数据之上的附加结构，其内部组织方式取决于所采用的<strong>近似最近邻搜索算法</strong>（Approximate Nearest Neighbor Search, ANNS）。索引的主要作用是加速搜索过程，但会带来以下代价：</p><ul><li>额外的预处理（构建）时间</li><li>占用更多存储空间</li><li>查询期间消耗更多 RAM</li><li>通常会略微降低<strong>召回率</strong>（recall rate），尽管影响通常可控</li></ul><p><strong>类比理解</strong>：索引就像书的目录，虽然占用了几页纸，但能让你快速找到想看的章节，而不用从头翻到尾。</p><p>因此，选择合适的索引需要在加速收益与上述成本之间找到平衡。</p><h2 id=支持的索引类型supported-index-types>支持的索引类型（Supported Index Types）</h2><p>Milvus 中的索引针对具体字段（field）定义，不同字段数据类型对应不同的适用索引。以下是官方支持的映射关系（重点关注向量索引）：</p><div class=table-wrapper><table><thead><tr><th>字段数据类型</th><th>适用索引类型</th></tr></thead><tbody><tr><td>FLOAT_VECTOR / FLOAT16_VECTOR / BFLOAT16_VECTOR / INT8_VECTOR</td><td>FLAT, IVF_FLAT, IVF_SQ8, IVF_PQ, IVF_RABITQ, HNSW, HNSW_SQ, HNSW_PQ, HNSW_PRQ, DISKANN, SCANN, AISAQ, GPU_CAGRA, GPU_IVF_FLAT, GPU_IVF_PQ, GPU_BRUTE_FORCE</td></tr><tr><td>BINARY_VECTOR</td><td>BIN_FLAT, BIN_IVF_FLAT, MINHASH_LSH</td></tr><tr><td>SPARSE_FLOAT_VECTOR</td><td>SPARSE_INVERTED_INDEX</td></tr><tr><td>VARCHAR</td><td>INVERTED（推荐）, BITMAP, Trie</td></tr><tr><td>BOOL</td><td>BITMAP（推荐）, INVERTED</td></tr><tr><td>INT8 / INT16 / INT32 / INT64</td><td>INVERTED, STL_SORT</td></tr><tr><td>FLOAT / DOUBLE</td><td>INVERTED</td></tr><tr><td>ARRAY（元素为 BOOL / INT8/16/32/64 / VARCHAR）</td><td>BITMAP（推荐）</td></tr><tr><td>ARRAY（元素为 BOOL / INT8/16/32/64 / FLOAT / DOUBLE / VARCHAR）</td><td>INVERTED</td></tr><tr><td>JSON</td><td>INVERTED</td></tr></tbody></table></div><p><strong>标量字段建议</strong>：优先使用表格中标注“推荐”的索引类型。本文重点讨论向量索引的选择。</p><h2 id=向量索引的内部结构vector-index-anatomy>向量索引的内部结构（Vector Index Anatomy）</h2><p>Milvus 的向量索引通常由三个核心组件构成：</p><ol><li><strong>数据结构</strong>（Data Structure）——用于粗粒度过滤</li><li><strong>量化</strong>（Quantization，可选）——压缩表示，减少内存和计算开销</li><li><strong>精炼器</strong>（Refiner，可选）——对量化后的候选结果使用更高精度重新计算距离，提升召回率</li></ol><p>索引构建时，Milvus 根据所选数据结构与量化方法自动确定一个合适的<strong>扩展率</strong>（expansion rate）。查询时，先检索 <code>topK × 扩展率</code> 个候选向量，再通过精炼器精排，最终返回最精确的 topK 结果。</p><h3 id=常见数据结构>常见数据结构</h3><ul><li><p><strong>倒排文件（Inverted File, IVF）</strong><br>通过质心（centroid）将向量聚类成多个桶。查询时仅扫描质心相近的桶，大幅减少计算量。<br><strong>适用场景</strong>：大规模数据集、高吞吐量需求。</p></li><li><p><strong>基于图的结构（Graph-based）</strong><br>以 HNSW（Hierarchical Navigable Small World）为代表，构建分层图结构，每个向量连接最近邻。查询从上层粗粒度逐步下沉，实现对数级时间复杂度。<br><strong>适用场景</strong>：高维数据、低延迟查询。</p></li></ul><h3 id=量化方法>量化方法</h3><ul><li><strong>标量量化（Scalar Quantization, SQ）</strong> 如 SQ8：每个维度压缩为 1 字节，内存减少约 75%，准确性损失可接受。</li><li><strong>乘积量化（Product Quantization, PQ）</strong>：将向量切分为子向量并编码，可实现 4–32 倍压缩，召回率略有下降，适合内存受限环境。</li></ul><h3 id=精炼器refiner>精炼器（Refiner）</h3><p>量化是有损的，为保证召回率，系统会产生更多候选；精炼器使用原始精度（如 FP32）对这些候选重新计算距离。这对语义搜索、推荐系统等距离敏感的应用至关重要。</p><h2 id=性能权衡与推荐使用场景>性能权衡与推荐使用场景</h2><p>选择索引时需综合考虑<strong>构建时间</strong>、<strong>查询吞吐（QPS）</strong>、<strong>召回率</strong>、<strong>内存/磁盘使用</strong>。</p><h3 id=容量capacity建议>容量（Capacity）建议</h3><p><strong>通俗解释</strong>：根据你的内存大小，选择合适的索引策略。</p><div class=table-wrapper><table><thead><tr><th>内存情况</th><th>推荐策略</th><th>说明</th></tr></thead><tbody><tr><td>原始数据 1/4 可放入内存</td><td>DiskANN</td><td>部分数据在内存，部分在磁盘，延迟稳定</td></tr><tr><td>全部数据可放入内存</td><td>内存索引 (HNSW/IVF) + mmap</td><td>速度最快，推荐使用</td></tr><tr><td>内存极度受限</td><td>量化索引 (IVF_PQ/IVF_SQ8) + mmap</td><td>压缩数据，牺牲精度换空间</td></tr><tr><td>大部分数据在磁盘</td><td>DiskANN</td><td>专为磁盘优化，延迟表现好</td></tr></tbody></table></div><p><strong>实际例子</strong>：</p><ul><li>你有 100 万条 128 维向量，原始数据约 500MB</li><li>如果你的服务器有 8GB 内存 → 用 HNSW（数据全部放内存）</li><li>如果你的服务器只有 2GB 内存 → 用 IVF_PQ（压缩到 100MB 以内）</li><li>如果你有 10 亿条向量（500GB）→ 用 DiskANN（磁盘索引）</li></ul><h3 id=召回率recall与过滤率filter-ratio>召回率（Recall）与过滤率（Filter Ratio）</h3><p><strong>通俗解释</strong>：根据你的筛选条件严格程度，选择合适的索引。</p><div class=table-wrapper><table><thead><tr><th>过滤率</th><th>剩余数据比例</th><th>推荐索引</th><th>原因</th></tr></thead><tbody><tr><td>&lt; 85%</td><td>剩余 > 15%</td><td>HNSW（图索引）</td><td>数据量还很大，需要高效索引</td></tr><tr><td>85%-95%</td><td>剩余 5%-15%</td><td>IVF 系列</td><td>中等数据量，聚类索引效果好</td></tr><tr><td>> 98%</td><td>剩余 &lt; 2%</td><td>FLAT（暴力搜索）</td><td>数据量很小，直接算更快</td></tr></tbody></table></div><p><strong>实际例子</strong>：</p><ul><li>100 万条数据，筛选"价格 > 1000"后剩 50 万条（过滤率 50%）→ 用 HNSW</li><li>100 万条数据，筛选"VIP 用户"后剩 10 万条（过滤率 90%）→ 用 IVF_FLAT</li><li>100 万条数据，筛选"今天注册的用户"后剩 100 条（过滤率 99.99%）→ 用 FLAT</li></ul><h3 id=性能决策矩阵推荐场景>性能决策矩阵（推荐场景）</h3><div class=table-wrapper><table><thead><tr><th>场景描述</th><th>推荐索引类型</th><th>说明备注</th></tr></thead><tbody><tr><td>原始数据全部可放入内存</td><td>HNSW, IVF + Refinement</td><td>HNSW 适合小 k / 高召回</td></tr><tr><td>原始数据在 SSD 磁盘</td><td>DiskANN</td><td>延迟敏感查询首选</td></tr><tr><td>原始数据在磁盘，RAM 有限</td><td>IVF_PQ / SQ + mmap</td><td>平衡内存与磁盘访问</td></tr><tr><td>高过滤率（>95%）</td><td>Brute-Force (FLAT)</td><td>避免索引开销</td></tr><tr><td>大 k（≥数据集 1%）</td><td>IVF</td><td>聚类剪枝减少计算量</td></tr><tr><td>极高召回率（>99%）</td><td>Brute-Force (FLAT) + GPU</td><td>—</td></tr></tbody></table></div><p><strong>一般规律</strong>：</p><ul><li>图索引（HNSW 等）QPS 通常高于 IVF 变体。</li><li>IVF 变体更适合大 topK（例如 >2000）。</li><li>PQ 在相同压缩率下召回率优于 SQ，但 SQ 速度更快。</li></ul><h2 id=实际应用场景推荐>实际应用场景推荐</h2><h3 id=场景-1电商商品推荐系统>场景 1：电商商品推荐系统</h3><p><strong>数据规模</strong>：100 万商品，每个商品 512 维向量
<strong>内存</strong>：16GB
<strong>需求</strong>：快速响应（&lt; 50ms），召回率 > 95%
<strong>推荐索引</strong>：HNSW
<strong>理由</strong>：数据能全部放入内存，HNSW 提供最佳的速度和召回率平衡</p><h3 id=场景-2大规模图片搜索>场景 2：大规模图片搜索</h3><p><strong>数据规模</strong>：1 亿张图片，每张 2048 维向量
<strong>内存</strong>：64GB
<strong>需求</strong>：支持高并发，可接受 100ms 延迟
<strong>推荐索引</strong>：DiskANN
<strong>理由</strong>：数据量太大无法全部放入内存，DiskANN 专为磁盘优化</p><h3 id=场景-3实时聊天机器人语义搜索>场景 3：实时聊天机器人（语义搜索）</h3><p><strong>数据规模</strong>：10 万条知识库，每条 768 维向量
<strong>内存</strong>：8GB
<strong>需求</strong>：极高召回率（> 99%），延迟 &lt; 20ms
<strong>推荐索引</strong>：FLAT（暴力搜索）
<strong>理由</strong>：数据量小，暴力搜索速度快且召回率 100%</p><h3 id=场景-4视频内容审核>场景 4：视频内容审核</h3><p><strong>数据规模</strong>：5000 万视频帧，每帧 256 维向量
<strong>内存</strong>：32GB（受限）
<strong>需求</strong>：成本优先，可接受 90% 召回率
<strong>推荐索引</strong>：IVF_PQ
<strong>理由</strong>：内存受限，PQ 压缩可节省 90% 内存</p><h3 id=场景-5用户画像匹配带过滤条件>场景 5：用户画像匹配（带过滤条件）</h3><p><strong>数据规模</strong>：500 万用户，每个用户 128 维向量
<strong>内存</strong>：16GB
<strong>需求</strong>：经常需要按”年龄、性别、地区”筛选后再搜索
<strong>推荐索引</strong>：</p><ul><li>向量字段：HNSW</li><li>标量字段（年龄、性别、地区）：INVERTED 或 BITMAP
<strong>理由</strong>：标量索引加速过滤，向量索引加速相似度搜索</li></ul><h3 id=场景-6新手快速开发原型>场景 6：新手快速开发原型</h3><p><strong>数据规模</strong>：不确定
<strong>内存</strong>：不确定
<strong>需求</strong>：快速上线，后续再优化
<strong>推荐索引</strong>：AUTOINDEX
<strong>理由</strong>：让系统自动选择，减少决策成本</p><h2 id=内存使用估算示例以-100-万个-128-维向量为例>内存使用估算示例（以 100 万个 128 维向量为例）</h2><h3 id=ivf-系列>IVF 系列</h3><ul><li>IVF_PQ（无精炼）：约 11 MB</li><li>IVF_PQ + 10% 原始精炼：约 62 MB</li><li>IVF_SQ8（无精炼）：约 131 MB</li><li>IVF_FLAT（全原始向量）：约 515 MB</li></ul><h3 id=hnsw-系列>HNSW 系列</h3><ul><li>HNSW（原始向量）：约 640 MB</li><li>HNSW_PQ（8 字节/向量）：约 136 MB</li></ul><p>精炼开销通常很小（例如 topK=10、扩展率=5 时约 25 KB）。</p><h2 id=度量类型详解metric-types>度量类型详解（Metric Types）</h2><h3 id=什么是度量类型>什么是度量类型？</h3><p><strong>度量类型</strong>（Metric Type）是用来衡量向量之间相似度的数学方法。选择合适的度量类型对分类和聚类性能有显著影响。</p><p><strong>类比理解</strong>：就像测量距离可以用"直线距离"、&ldquo;步行距离&rdquo;、&ldquo;开车距离&rdquo;，向量相似度也有不同的计算方法，不同方法适用于不同场景。</p><h3 id=支持的度量类型映射表>支持的度量类型映射表</h3><div class=table-wrapper><table><thead><tr><th>字段类型</th><th>维度范围</th><th>支持的度量类型</th><th>默认度量类型</th></tr></thead><tbody><tr><td>FLOAT_VECTOR</td><td>2-32,768</td><td>COSINE, L2, IP</td><td>COSINE</td></tr><tr><td>FLOAT16_VECTOR</td><td>2-32,768</td><td>COSINE, L2, IP</td><td>COSINE</td></tr><tr><td>BFLOAT16_VECTOR</td><td>2-32,768</td><td>COSINE, L2, IP</td><td>COSINE</td></tr><tr><td>INT8_VECTOR</td><td>2-32,768</td><td>COSINE, L2, IP</td><td>COSINE</td></tr><tr><td>SPARSE_FLOAT_VECTOR</td><td>无需指定维度</td><td>IP, BM25（仅用于全文搜索）</td><td>IP</td></tr><tr><td>BINARY_VECTOR</td><td>8-32,768*8</td><td>HAMMING, JACCARD, MHJACCARD</td><td>HAMMING</td></tr></tbody></table></div><p><strong>注意事项</strong>：</p><ul><li>BINARY_VECTOR 的维度必须是 8 的倍数</li><li>BM25 仅用于 SPARSE_FLOAT_VECTOR 的全文搜索场景</li></ul><h3 id=度量类型特征对比>度量类型特征对比</h3><div class=table-wrapper><table><thead><tr><th>度量类型</th><th>相似度特征</th><th>取值范围</th><th>说明</th></tr></thead><tbody><tr><td>L2</td><td>值越小越相似</td><td>[0, ∞)</td><td>欧氏距离</td></tr><tr><td>IP</td><td>值越大越相似</td><td>[-1, 1]</td><td>内积</td></tr><tr><td>COSINE</td><td>值越大越相似</td><td>[-1, 1]</td><td>余弦相似度</td></tr><tr><td>JACCARD</td><td>值越小越相似</td><td>[0, 1]</td><td>杰卡德距离</td></tr><tr><td>MHJACCARD</td><td>值越小越相似</td><td>[0, 1]</td><td>MinHash 杰卡德估计</td></tr><tr><td>HAMMING</td><td>值越小越相似</td><td>[0, dim(vector)]</td><td>汉明距离</td></tr><tr><td>BM25</td><td>分数越高越相关</td><td>[0, ∞)</td><td>文本相关性评分</td></tr></tbody></table></div><h3 id=1-欧氏距离l2>1. 欧氏距离（L2）</h3><p><strong>定义</strong>：测量两点之间的直线距离。</p><p><strong>公式</strong>：</p><pre tabindex=0><code>d(a, b) = √(Σ(ai - bi)²)
</code></pre><p>其中 a = (a0, a1, &mldr;, an-1) 和 b = (b0, b1, &mldr;, bn-1) 是 n 维空间中的两个点。</p><p><strong>特点</strong>：</p><ul><li>最常用的距离度量</li><li>适用于连续数据</li><li>Milvus 实际计算时不开平方根（提升性能）</li></ul><p><strong>适用场景</strong>：</p><ul><li>图像相似度搜索（如人脸识别）</li><li>通用向量搜索</li><li>数据分布均匀的场景</li></ul><p><strong>实际例子</strong>：</p><ul><li>两张人脸照片的特征向量，L2 距离越小表示越像同一个人</li><li>商品特征向量，L2 距离小的商品属性更接近</li></ul><h3 id=2-内积ip-inner-product>2. 内积（IP, Inner Product）</h3><p><strong>定义</strong>：两个向量的内积值。</p><p><strong>公式</strong>：</p><pre tabindex=0><code>IP(a, b) = Σ(ai × bi)
</code></pre><p><strong>特点</strong>：</p><ul><li>值越大表示越相似</li><li>考虑向量的大小（magnitude）和角度</li><li>适用于非归一化数据</li></ul><p><strong>重要提示</strong>：</p><ul><li>如果使用 IP 计算相似度，<strong>必须先归一化向量</strong></li><li>归一化后，IP 等价于余弦相似度</li></ul><p><strong>适用场景</strong>：</p><ul><li>推荐系统（用户-物品评分预测）</li><li>需要考虑向量大小的场景</li><li>已归一化的向量数据</li></ul><p><strong>实际例子</strong>：</p><ul><li>用户对电影的评分预测，IP 值越大表示用户越喜欢该电影</li><li>文档相关性排序</li></ul><h3 id=3-余弦相似度cosine>3. 余弦相似度（COSINE）</h3><p><strong>定义</strong>：使用两个向量之间的夹角余弦值来衡量相似度。</p><p><strong>公式</strong>：</p><pre tabindex=0><code>cosine(a, b) = (Σ(ai × bi)) / (√(Σai²) × √(Σbi²))
</code></pre><p><strong>特点</strong>：</p><ul><li>取值范围 [-1, 1]</li><li>只关注方向，不关注大小</li><li>1 表示完全相同方向，0 表示正交，-1 表示完全相反</li></ul><p><strong>适用场景</strong>（最常用）：</p><ul><li>文本相似度（NLP）</li><li>语义搜索</li><li>推荐系统</li><li>任何需要忽略向量大小的场景</li></ul><p><strong>实际例子</strong>：</p><ul><li>两篇文章的语义相似度，COSINE 值越大表示主题越相近</li><li>用户兴趣向量匹配，COSINE 值高表示兴趣相似</li><li>OpenAI/Cohere 等模型的 embedding 默认使用 COSINE</li></ul><h3 id=4-杰卡德距离jaccard>4. 杰卡德距离（JACCARD）</h3><p><strong>定义</strong>：衡量两个集合的相似度，等于交集大小除以并集大小。</p><p><strong>公式</strong>：</p><pre tabindex=0><code>JACCARD 相似度 = |A ∩ B| / |A ∪ B|
JACCARD 距离 = 1 - JACCARD 相似度
</code></pre><p><strong>特点</strong>：</p><ul><li>仅适用于有限样本集</li><li>取值范围 [0, 1]</li><li>对于二进制变量，等价于 Tanimoto 系数</li></ul><p><strong>适用场景</strong>：</p><ul><li>二进制向量（BINARY_VECTOR）</li><li>集合相似度比较</li><li>标签匹配</li></ul><p><strong>实际例子</strong>：</p><ul><li>用户标签匹配：用户 A 标签 {科技, 音乐, 旅游}，用户 B 标签 {科技, 电影, 旅游}，交集 2 个，并集 4 个，JACCARD 相似度 = 2/4 = 0.5</li><li>文档关键词重叠度</li></ul><h3 id=5-minhash-杰卡德mhjaccard>5. MinHash 杰卡德（MHJACCARD）</h3><p><strong>定义</strong>：使用 MinHash 签名快速估计杰卡德相似度的方法。</p><p><strong>特点</strong>：</p><ul><li>比精确计算 JACCARD 快得多</li><li>适用于大规模或高维场景</li><li>距离 = 1 - 估计相似度</li></ul><p><strong>适用场景</strong>：</p><ul><li>大规模文档集合相似度</li><li>用户标签集合匹配</li><li>基因组 k-mer 集合比较</li></ul><p><strong>实际例子</strong>：</p><ul><li>海量网页去重</li><li>大规模用户群体相似度分析</li></ul><h3 id=6-汉明距离hamming>6. 汉明距离（HAMMING）</h3><p><strong>定义</strong>：两个等长二进制串中不同位的数量。</p><p><strong>公式</strong>：</p><pre tabindex=0><code>例如：11011001 ⊕ 10011101 = 01000100
包含 2 个 1，所以 HAMMING 距离 = 2
</code></pre><p><strong>特点</strong>：</p><ul><li>仅适用于二进制数据</li><li>取值范围 [0, dim(vector)]</li><li>计算速度极快</li></ul><p><strong>适用场景</strong>：</p><ul><li>二进制特征向量（BINARY_VECTOR）</li><li>图像哈希匹配</li><li>错误检测与纠正</li></ul><p><strong>实际例子</strong>：</p><ul><li>图像感知哈希（pHash）相似度比较</li><li>二进制指纹匹配</li></ul><h3 id=7-bm25-相似度>7. BM25 相似度</h3><p><strong>定义</strong>：专为全文搜索设计的文本相关性评分方法。</p><p><strong>核心因素</strong>：</p><ol><li><strong>词频（TF）</strong>：词在文档中出现的频率</li><li><strong>逆文档频率（IDF）</strong>：词在整个语料库中的重要性</li><li><strong>文档长度归一化</strong>：避免长文档得分偏高</li></ol><p><strong>公式</strong>：</p><pre tabindex=0><code>score(D, Q) = Σ IDF(qi) × [TF(qi, D) × (k1 + 1)] / [TF(qi, D) + k1 × (1 - b + b × |D|/avgdl)]
</code></pre><p><strong>参数说明</strong>：</p><ul><li><strong>k1</strong>：控制词频影响，典型范围 [1.2, 2.0]，Milvus 允许 [0, 3]</li><li><strong>b</strong>：控制长度归一化程度，范围 [0, 1]<ul><li>b=0：不归一化</li><li>b=1：完全归一化</li></ul></li><li><strong>avgdl</strong>：语料库中文档的平均长度</li></ul><p><strong>适用场景</strong>：</p><ul><li>全文搜索（SPARSE_FLOAT_VECTOR）</li><li>文档检索</li><li>问答系统</li></ul><p><strong>实际例子</strong>：</p><ul><li>搜索引擎关键词匹配</li><li>知识库问答相关性排序</li></ul><h3 id=如何选择度量类型>如何选择度量类型？</h3><div class=table-wrapper><table><thead><tr><th>应用场景</th><th>推荐度量类型</th><th>理由</th></tr></thead><tbody><tr><td>语义搜索、NLP</td><td>COSINE</td><td>只关注方向，不受向量大小影响</td></tr><tr><td>图像搜索、人脸识别</td><td>L2</td><td>直观的距离度量，适合连续特征</td></tr><tr><td>推荐系统（归一化向量）</td><td>COSINE 或 IP</td><td>归一化后两者等价</td></tr><tr><td>推荐系统（非归一化）</td><td>IP</td><td>考虑评分大小</td></tr><tr><td>二进制特征匹配</td><td>HAMMING</td><td>速度快，适合二进制数据</td></tr><tr><td>集合相似度</td><td>JACCARD</td><td>适合标签、关键词匹配</td></tr><tr><td>全文搜索</td><td>BM25</td><td>专为文本检索设计</td></tr><tr><td>大规模集合匹配</td><td>MHJACCARD</td><td>快速估计，适合海量数据</td></tr></tbody></table></div><h3 id=使用示例>使用示例</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 向量字段使用不同度量类型</span>
</span></span><span style=display:flex><span>index_params<span style=color:#f92672>.</span>add_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;embedding&#34;</span>,
</span></span><span style=display:flex><span>    index_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;HNSW&#34;</span>,
</span></span><span style=display:flex><span>    metric_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;COSINE&#34;</span>  <span style=color:#75715e># 语义搜索推荐</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>index_params<span style=color:#f92672>.</span>add_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;image_vector&#34;</span>,
</span></span><span style=display:flex><span>    index_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;IVF_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    metric_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;L2&#34;</span>  <span style=color:#75715e># 图像搜索推荐</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>index_params<span style=color:#f92672>.</span>add_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;binary_features&#34;</span>,
</span></span><span style=display:flex><span>    index_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;BIN_FLAT&#34;</span>,
</span></span><span style=display:flex><span>    metric_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;HAMMING&#34;</span>  <span style=color:#75715e># 二进制特征推荐</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>index_params<span style=color:#f92672>.</span>add_index(
</span></span><span style=display:flex><span>    field_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sparse_vector&#34;</span>,
</span></span><span style=display:flex><span>    index_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;SPARSE_INVERTED_INDEX&#34;</span>,
</span></span><span style=display:flex><span>    metric_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;BM25&#34;</span>  <span style=color:#75715e># 全文搜索推荐</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><h3 id=性能对比>性能对比</h3><div class=table-wrapper><table><thead><tr><th>度量类型</th><th>计算速度</th><th>内存占用</th><th>精度</th><th>适用数据类型</th></tr></thead><tbody><tr><td>HAMMING</td><td>极快</td><td>极低</td><td>精确</td><td>二进制</td></tr><tr><td>L2</td><td>快</td><td>中等</td><td>精确</td><td>浮点数</td></tr><tr><td>IP</td><td>快</td><td>中等</td><td>精确</td><td>浮点数</td></tr><tr><td>COSINE</td><td>中等</td><td>中等</td><td>精确</td><td>浮点数</td></tr><tr><td>JACCARD</td><td>中等</td><td>低</td><td>精确</td><td>二进制/集合</td></tr><tr><td>MHJACCARD</td><td>快</td><td>低</td><td>近似</td><td>二进制/集合</td></tr><tr><td>BM25</td><td>中等</td><td>中等</td><td>精确</td><td>稀疏向量</td></tr></tbody></table></div><h2 id=总结>总结</h2><p>Milvus 的向量索引采用分层架构（粗过滤 → 量化压缩 → 精炼提升精度），能够自适应地优化准确性与性能的权衡。实际选择时，建议结合<strong>数据规模</strong>、<strong>硬件环境</strong>（内存/磁盘/GPU）、<strong>查询模式</strong>（topK 大小、过滤率）和<strong>业务对召回率的要求</strong>进行实验调优，而非一刀切。</p><p><strong>关键决策点</strong>：</p><ol><li><strong>选择索引类型</strong>：根据容量、召回率、过滤率选择（HNSW/IVF/DiskANN/FLAT）</li><li><strong>选择度量类型</strong>：根据数据特征和应用场景选择（COSINE/L2/IP/HAMMING/BM25）</li><li><strong>调优参数</strong>：根据实际测试结果微调索引参数和搜索参数</li></ol></section><footer class=article-footer><section class=article-tags><a href=/tags/milvus/>Milvus</a>
<a href=/tags/index/>Index</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/stu/milvus-collection-operations/><div class=article-details><h2 class=article-title>Milvus 集合操作详解</h2></div></a></article><article><a href=/stu/milvus-stu-schema/><div class=article-details><h2 class=article-title>Milvus Schema模式详解 - 字段类型与数据建模指南</h2></div></a></article><article><a href=/stu/milvus-stu-db/><div class=article-details><h2 class=article-title>Milvus数据库操作</h2></div></a></article><article><a href=/stu/milvus-install-guide/><div class=article-details><h2 class=article-title>Milvus Standalone 模式安装完整指南及常见问题解决</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=zg-dd/zg-dd.github.io data-repo-id=R_kgDOQwB7tw data-category=Announcements data-category-id=DIC_kwDOQwB7t84C0WGD data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"preferred_color_scheme":"preferred_color_scheme")}})()</script><footer class=site-footer><section class=copyright>&copy;
2026 小巷的随笔</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>